# LAB: CNN Object Detection (Free Topic)



# I. Introduction

In this lab, you are required to create a simple application that uses a CNN-based object detection. You are free to choose the application topic of your interest. 



## Application Examples 

Choose a topic relevant to Mechatronics. [Refer to past lab reports on object detection](https://ykkim.gitbook.io/dlip/dlip-project/dlip-projects)

> YOU MUST NOT choose the  same topic of previous labs

*  [Kaggle Data Challenge](https://www.kaggle.com/competitions)
*  Defect detection
*  Face recognition 
*  Pedestrian/Vehicle/Signpost detection for autonomous driving
*   [People/vehicle Counting](https://www.youtube.com/watch?v=19vaot75JCY) 
*   [Anomaly detection](https://towardsdatascience.com/anomaly-detection-in-images-777534980aeb) and more



## Guidelines

The whole code should be programmed using OpenCV-Python and Pytorch. 

* DO NOT copy a project from online sites.

* You can refer to any online material and github repository for assistance and getting ideas with proper reference citation. 

* You can use any pretrained object detection model, such as YOLO v3~v5, etc..

* You may also train the model using custom datasets

* You can clone a github repository of the object detection model(e.g. YOLOv5), as long as you cite it in the reference.

  

If you create a simple hardware for demonstration, you will get extra score.  Please ask TA if you need an embedded GPU board or any other hardware materials. 



# II. Report and Demo Video

 

This lab will be scored depending on the Contents, Complexity, and Completeness .

You are required to write a concise report and submit the program files and the demo video.



## Report 

The lab report must be written as a 'Tutorial' format to explain the whole process A to Z in detail. Your report will be posted in the class website and be open to public.

A high score will be given if a reader should be able to follow the report instructions and get the same results.

Use the report template given here: https://ykkim.gitbook.io/dlip/dlip-project/report-template  

*  Also, see example tutorials: [example 1](https://keras.io/examples/vision/retinanet/), [example 2](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb)



**Requirement**

* Write the report in markdown ‘*.md’ format   

* You need to include concise explanations and codes for each process in the report 

* Upload the source code and report in your github repository (Open, Public):  

  * Repository name example:  DLIP_Project_keywords_2022,     keywords: MaskDetection,  PedestrianCounting, etc..

* Download your repository as zip file and submit the zip file to online.handong.edu.  The Zip file  includes 

  * Report (*.md) 
  * Report (*.pdf)
  * src  (source code)
  * images (sample, test image files )
  * data (whole dataset or download link)

  

  


## Demo Video

You must create a demo video (~40 sec) that will be uploaded in the Lecture's Youtube channel.



* The demo video must contain
  * Title page:  course name (DLIP2022-1 by Y.-K.Kim), your name, your project tile, date
  * Introduction, Dataset, Model, Results, Conclusion

* Embed the youtube video in your report
* Submit the video file to LMS or  TA's email




